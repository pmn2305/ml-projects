{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6z4LxK_Ej7E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbWRpBVAqYZq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.applications.resnet50 import ResNet50 , preprocess_input\n",
        "from numpy.linalg import norm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hiteshsuthar101/myntra-fashion-product-dataset"
      ],
      "metadata": {
        "id": "M2A847Sxqxg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3597eea9-6cfc-4a41-e851-5f6df40abd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading myntra-fashion-product-dataset.zip to /content\n",
            "100% 2.90G/2.90G [00:30<00:00, 129MB/s]\n",
            "100% 2.90G/2.90G [00:30<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zipref = zipfile.ZipFile('myntra-fashion-product-dataset.zip')\n",
        "zipref.extractall()\n",
        "zipref.close()"
      ],
      "metadata": {
        "id": "hgKjJAkEq2Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvXNaYPDua1D",
        "outputId": "55111f67-eeff-4316-83cf-8f944b222397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "472 Anouk X Earthful Women White & Pink Floral Printed A-Line Kurta http://assets.myntassets.com/assets/images/16272186/2022/4/12/3fbb2568-3dd1-472a-9971-d9c1c5d800931649758997074-Anouk-Women-White--Pink-Floral-Printed-Pastels-Kurta-2581649-1.jpg Rs.4799.0\n",
            "480 Anouk Women White & Blue Floral Printed Kurta http://assets.myntassets.com/assets/images/16190856/2022/5/6/60bc83ec-edd9-4d28-ae8d-1efc66afcbfe1651820015650-Anouk-Women-Kurtas-61651820015285-5.jpg Rs.3399.0\n",
            "516 HERE&NOW Women Blue & White Striped Embroidered Mirror Work A-Line Kurta http://assets.myntassets.com/assets/images/17279494/2022/5/10/b9fd2236-0ea1-4990-91c9-d3ea95768c5c1652164055648-HERENOW-Women-Kurtas-7801652164055110-1.jpg Rs.1699.0\n",
            "288 Anouk Women Black & White Bandhani Printed Halter Neck Kurta http://assets.myntassets.com/assets/images/18533904/2022/6/17/3587d447-0b2a-4326-b5e2-fb439066331b1655443585896-Anouk-Women-Kurtas-2981655443585291-1.jpg Rs.2999.0\n",
            "648 Anouk Women Pink Pure Cotton Solid Kurta http://assets.myntassets.com/assets/images/17093944/2022/5/7/566c5d81-4c45-4c05-b6ef-ee7c0fcb17a71651915003433-Anouk-Women-Pink-Pure-Cotton-Solid-Kurta-3821651915002848-1.jpg Rs.3299.0\n",
            "210 Anouk Women Red & White Bandhani Printed Angrakha Gotta Patti A-Line Kurta http://assets.myntassets.com/assets/images/17417200/2022/4/20/4d8b74a3-262f-410c-9302-8555cbe98c6e1650444576842-Anouk-Women-Kurtas-6521650444576386-1.jpg Rs.4498.0\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "\n",
        "import ast\n",
        "df=pd.read_csv(\"/content/Fashion Dataset.csv\")\n",
        "df.head()\n",
        "df_c=df.dropna()\n",
        "df_c=df_c[[\"name\",\"colour\",\"brand\",\"description\",\"p_attributes\",\"img\",\"price\"]]\n",
        "def convert(ob):\n",
        "    l=[]\n",
        "    for i,j in ob.items():\n",
        "        if i==[\"Number of Pockets\"]:\n",
        "            l.append(v[i])\n",
        "    return l\n",
        "def convertd(df):\n",
        "    v=ast.literal_eval(df)\n",
        "\n",
        "\n",
        "    l=[]\n",
        "    for i in v.keys():\n",
        "        if i in [\"Number of Pockets\",\"Stitch\",\"Wash Care\"]:\n",
        "            l.append(v[i])\n",
        "\n",
        "    return l\n",
        "\n",
        "df_c[\"p_attributes\"]=df_c[\"p_attributes\"].apply(convertd)\n",
        "def list_conv(text):\n",
        "    l=[]\n",
        "    for i in text.split():\n",
        "        l.append(i)\n",
        "    return l\n",
        "df_c[\"brand\"]=df_c[\"brand\"].apply(list_conv)\n",
        "df_c[\"brand\"]=df_c[\"brand\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
        "df_c[\"colour\"]=df_c[\"colour\"].apply(list_conv)\n",
        "df_c[\"colour\"]=df_c[\"colour\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
        "df_c[\"p_attributes\"]=df_c[\"p_attributes\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
        "df_c[\"description\"]=df_c[\"description\"].apply(list_conv)\n",
        "df_c\n",
        "df_c[\"Tag\"]=df_c[\"colour\"]+df_c[\"brand\"]+df_c[\"description\"]+df_c[\"p_attributes\"]\n",
        "def st(text):\n",
        "    l=[]\n",
        "    for i in text.split():\n",
        "        l.append(ps.stem(i))\n",
        "    return \" \".join(l)\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps=PorterStemmer()\n",
        "df_c[\"Tag\"]=df_c[\"Tag\"].apply(lambda x: \" \".join(x))\n",
        "df_c[\"Tag\"]=df_c[\"Tag\"].apply(st)\n",
        "df_c=df_c[[\"name\",\"Tag\",\"img\"]]\n",
        "df_c\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=6000,stop_words=\"english\")\n",
        "vectors=cv.fit_transform(df_c[\"Tag\"]).toarray()\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Calculate cosine distances between vectors\n",
        "distances = cosine_distances(vectors)\n",
        "def similar_images(movie):\n",
        "    index = df_c[df_c[\"name\"] == movie].index[0]\n",
        "    distance = distances[index]\n",
        "    # Sort distances in ascending order to find similar images\n",
        "    list_v = sorted(list(enumerate(distance)), key=lambda x: x[1])[:6]  # Change [1:6] to [0:6] to include the input image\n",
        "\n",
        "    for i in list_v:\n",
        "        c = i[0]\n",
        "        print(c, df_c.iloc[c][\"name\"], df_c.iloc[c][\"img\"], 'Rs.' + str(df.iloc[c][\"price\"]))\n",
        "\n",
        "similar_images(\"Khushal K Women White Ethnic Motifs Printed Gotta Patti Kurta with Palazzos & With Dupatta\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the fashion dataset CSV file\n",
        "df = pd.read_csv(\"/content/Fashion Dataset.csv\")\n",
        "\n",
        "# Define file paths for different categories\n",
        "category_files = {\n",
        "    \"outfit\": \"outfit_items.csv\",\n",
        "    \"top\": \"top_items.csv\",\n",
        "    \"pants\": \"pants_items.csv\",\n",
        "}\n",
        "\n",
        "# Function to determine category based on keywords in the name\n",
        "def get_category(name):\n",
        "    name = name.lower()  # Convert to lowercase for case-insensitive matching\n",
        "    if any(keyword in name for keyword in [\"dupatta\",'lehenga','saree',\"kurti\", \"kurta\", \"palazzos\",'tunic','jumpsuit','dress','co-ord','playsuit']):\n",
        "        return \"outfit\"\n",
        "    elif any(keyword in name for keyword in [\"top\",\"jacket\",\"blazer\",\"shrug\",\"pullover\",\"sweatshirt\",\"sweater\",\"cardigan\"]):\n",
        "        return \"top\"\n",
        "    elif any(keyword in name for keyword in [\"pants\",\"leggings\", \"jeans\",\"trousers\",'joggers',\"culottes\",]):\n",
        "        return \"pants\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Iterate through each row of the \"name\" column and write to respective category files\n",
        "for index, row in df.iterrows():\n",
        "    name = row[\"name\"]\n",
        "    if isinstance(name, str):\n",
        "        category = get_category(name)\n",
        "        if category:\n",
        "            with open(category_files[category], \"a\") as f:\n",
        "                f.write(','.join(map(str, row)) + '\\n')\n",
        "        else:\n",
        "            print(f\"No category found for item '{name}'. Skipping...\")\n",
        "    else:\n",
        "        print(f\"Invalid name for item at index {index}. Skipping...\")\n",
        "\n",
        "print(\"Rows appended to respective category files.\")\n"
      ],
      "metadata": {
        "id": "x0DqKrp3ue6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the top and pant items data\n",
        "top_items_df = pd.read_csv('/content/top_items_desc.csv')\n",
        "pant_items_df = pd.read_csv('/content/pants_items_desc.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "top_items_descriptions = top_items_df['description'].fillna('')\n",
        "pant_items_descriptions = pant_items_df['description'].fillna('')\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit TF-IDF vectorizer on top items descriptions\n",
        "tfidf_vectorizer.fit(top_items_descriptions)\n",
        "\n",
        "# Transform top and pant items descriptions to TF-IDF vectors\n",
        "top_items_tfidf = tfidf_vectorizer.transform(top_items_descriptions)\n",
        "pant_items_tfidf = tfidf_vectorizer.transform(pant_items_descriptions)\n",
        "\n",
        "# Compute cosine similarity between top and pant items\n",
        "cosine_similarities = cosine_similarity(top_items_tfidf, pant_items_tfidf)\n"
      ],
      "metadata": {
        "id": "Mf3K-fNxuVCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_pant_for_top(top_description):\n",
        "    top_tfidf = tfidf_vectorizer.transform([top_description])\n",
        "    similarities = cosine_similarity(top_tfidf, pant_items_tfidf)\n",
        "\n",
        "    # Take the negative of cosine similarity to emphasize complementarity\n",
        "    complementarity_scores = -similarities\n",
        "\n",
        "    best_pant_indices = complementarity_scores.argsort(axis=None)[-5:][::-1]\n",
        "\n",
        "    return pant_items_df.iloc[best_pant_indices]\n",
        "\n",
        "def recommend_top_for_pant(pant_description):\n",
        "\n",
        "    pant_tfidf = tfidf_vectorizer.transform([pant_description])\n",
        "\n",
        "    similarities = cosine_similarity(top_items_tfidf, pant_tfidf)\n",
        "\n",
        "    # Take the negative of cosine similarity to emphasize complementarity\n",
        "    complementarity_scores = -similarities\n",
        "\n",
        "    best_top_indices = complementarity_scores.argsort(axis=None)[-5:][::-1]\n",
        "\n",
        "    return top_items_df.iloc[best_top_indices]\n"
      ],
      "metadata": {
        "id": "v15vYFrNPsO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "# Get user input for a top description\n",
        "user_top_description = input(\"Enter the description of the top: \")\n",
        "\n",
        "# Recommend complementary pant items for the entered top description\n",
        "recommended_pants = recommend_pant_for_top(user_top_description)\n",
        "print(\"\\nRecommended Pant Items:\")\n",
        "print(recommended_pants[['name', 'img', 'price']])\n",
        "\n",
        "# Get user input for a pant description\n",
        "user_pant_description = input(\"\\nEnter the description of the pant: \")\n",
        "\n",
        "# Recommend complementary top items for the entered pant description\n",
        "recommended_tops = recommend_top_for_pant(user_pant_description)\n",
        "print(\"\\nRecommended Top Items:\")\n",
        "print(recommended_tops[['name', 'img', 'price']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLea8-OFQdfz",
        "outputId": "7cf67a9e-2d4d-426d-ecf4-e658828e07e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the description of the top: white shirt\n",
            "\n",
            "Recommended Pant Items:\n",
            "                                                                                     name  \\\n",
            "978                             BoStreet Women Black Loose Fit High-Rise Hot Pants Shorts   \n",
            "676  SHOWOFF Women Blue Boyfriend Fit High-Rise Low Distress Light Fade Stretchable Jeans   \n",
            "648                                Campus Sutra Women Navy Blue Slim Fit Heavy Fade Jeans   \n",
            "649                            URBANIC Women Blue Straight Fit Stylized Stretchable Jeans   \n",
            "650                                      GOLDSTROMS Women Blue Slim Fit Stretchable Jeans   \n",
            "\n",
            "                                                                                                                                                                                  img  \\\n",
            "978                                                        http://assets.myntassets.com/assets/images/18458288/2022/5/27/8b64ea90-ab79-4a6e-ae86-cd393a830c941653660239512Shorts1.jpg   \n",
            "676  http://assets.myntassets.com/assets/images/17570446/2022/3/19/e88937cb-6d56-47f6-ba12-22ef2a7ff2b41647678607744SHOWOFFWomenBlueBoyfriendFitHigh-RiseLowDistressLightFadeStr1.jpg   \n",
            "648     http://assets.myntassets.com/assets/images/16200984/2021/11/22/ef27cabd-b59c-4205-9541-35a08ddbcb411637576224077CampusSutraWomenNavyBlueSlimFitLowDistressHeavyFadeJeans1.jpg   \n",
            "649                        http://assets.myntassets.com/assets/images/16262850/2022/3/28/c2976742-a854-429f-ad6e-0b0bc7fb533d1648450746828-URBANIC-Women-Jeans-8841648450746273-1.jpg   \n",
            "650                   http://assets.myntassets.com/assets/images/16169572/2021/11/19/5aba1f8b-40f8-485b-b648-4a6c28e038d31637314389279GOLDSTROMSWomenBlueSlimFitStretchableJeans1.jpg   \n",
            "\n",
            "    price  \n",
            "978  1699  \n",
            "676  3720  \n",
            "648  1899  \n",
            "649  1790  \n",
            "650  1399  \n",
            "\n",
            "Enter the description of the pant: black baggy jeans\n",
            "\n",
            "Recommended Top Items:\n",
            "                                                             name  \\\n",
            "3890        Vero Moda Women Grey & Green Colourblocked Sweatshirt   \n",
            "1414  Janasya Women Blue Conversational Print Pleated Regular Top   \n",
            "1428           Indya X Payal Singhal Orange Foil Strappy Crop Top   \n",
            "1426             Janasya Blue Striped Tie-Up Neck Pure Cotton Top   \n",
            "1425   Rangriti Women White & Pink Embroidered Ethnic Printed Top   \n",
            "\n",
            "                                                                                                                                                               img  \\\n",
            "3890  http://assets.myntassets.com/assets/images/16379656/2021/12/6/ea63e0df-fe70-46c2-aea9-7b6a167f49371638781179533VeroModaWomenGreyColourblockedSweatshirt1.jpg   \n",
            "1414                                      http://assets.myntassets.com/assets/images/productimage/2021/7/6/b47a14b9-ee31-493c-aa63-cf083b4f01f41625559459165-1.jpg   \n",
            "1428            http://assets.myntassets.com/assets/images/15595764/2021/9/23/ec83a14d-175a-41d6-b626-999992ba8cb91632411110835INDYAOrangeFloralFittedCropTop1.jpg   \n",
            "1426                                     http://assets.myntassets.com/assets/images/productimage/2021/2/17/007be19f-6693-412e-bdf6-d874a6730dd81613545519392-1.jpg   \n",
            "1425     http://assets.myntassets.com/assets/images/11362372/2020/6/4/41684b32-603a-42e1-ac89-9959b0fdbf591591246687917-Rangriti-Women-Tops-8601591246687002-1.jpg   \n",
            "\n",
            "     price  \n",
            "3890  2299  \n",
            "1414  1299  \n",
            "1428  1400  \n",
            "1426  1498  \n",
            "1425   999  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8p_tPqfYXhkP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}